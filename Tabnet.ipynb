{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WZHFma3ziCAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b82d17-a72e-45ca-939c-1f17e0e66c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "data = np.load('/content/drive/MyDrive/Xy_train.npz')\n",
        "X_train = pd.DataFrame(data['X'])\n",
        "y_train = pd.DataFrame(data['y'])\n",
        "data = np.load(\"/content/drive/MyDrive/X_test.npz\")\n",
        "X_test = pd.DataFrame(data['X'])"
      ],
      "metadata": {
        "id": "J8ILh00Ii8xB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_train.append(X_test)\n",
        "X.index = range(X.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LkHirODPIds",
        "outputId": "a09469ed-2a8f-4633-f087-d59e822a1d95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e718d2be2b37>:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X = X_train.append(X_test)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.columns = [str(i) for i in range(X.shape[1])]\n",
        "y_train.columns = ['y']"
      ],
      "metadata": {
        "id": "MBQlNnf_h6A-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(X.shape[1]):\n",
        "  if (len(X[str(i)].unique()) < 100):\n",
        "    X[str(i)] = X[str(i)].astype('object')"
      ],
      "metadata": {
        "id": "3RjAI8QcR75D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "ayWAdYozrDRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(X.isna().sum())"
      ],
      "metadata": {
        "id": "LtU-Vo0qqqMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_total = X_train.shape[0]\n",
        "train_indices, valid_indices = train_test_split(range(n_total), test_size=0.2, random_state=42)\n",
        "test_indices = [int(i) for i in range(400000,500000)]"
      ],
      "metadata": {
        "id": "XsiZKOhGn19Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "categorical_columns = []\n",
        "categorical_dims =  {}\n",
        "for col in X.columns[X.dtypes == 'object']:\n",
        "    print(col, X[col].nunique())\n",
        "    l_enc = LabelEncoder()\n",
        "    X[col] = l_enc.fit_transform(X[col].values)\n",
        "    categorical_columns.append(col)\n",
        "    categorical_dims[col] = len(l_enc.classes_)"
      ],
      "metadata": {
        "id": "QTj300LxotfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_idxs = [int(i) for i in categorical_columns]\n",
        "cat_dims = [categorical_dims[f] for f in categorical_columns]"
      ],
      "metadata": {
        "id": "oZ7V1yXHpkNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(X_train.columns)"
      ],
      "metadata": {
        "id": "gnqX1ew_scl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = X[features].values[train_indices]\n",
        "trainy = y_train['y'].values[train_indices]\n",
        "testX = X[features].values[test_indices]\n",
        "\n",
        "valX = X[features].values[valid_indices]\n",
        "valy = y_train['y'].values[valid_indices]"
      ],
      "metadata": {
        "id": "5ZC-g7wus4-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "metadata": {
        "id": "atdZuix8zGuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import torch\n",
        "clf = TabNetClassifier(\n",
        "    n_d=64, n_a=64, n_steps=3,\n",
        "    gamma=1.5, seed = 42,\n",
        "    cat_idxs=cat_idxs,\n",
        "    cat_dims=cat_dims,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=1e-2),\n",
        "    scheduler_params = {\"gamma\": 0.9,\n",
        "                     \"step_size\": 10},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR\n",
        ")\n",
        "clf.fit(\n",
        "  trainX, trainy,\n",
        "  eval_set=[(trainX, trainy),(valX, valy)],\n",
        "  eval_metric = ['balanced_accuracy'],\n",
        "  max_epochs = 200,\n",
        "  compute_importance = False,\n",
        "  batch_size= 1024,\n",
        "  virtual_batch_size=1024,\n",
        "  patience = 30,\n",
        "  )\n",
        "saved_filename = clf.save_model('test_model')"
      ],
      "metadata": {
        "id": "wBmW6J2pxpZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(testX)"
      ],
      "metadata": {
        "id": "oXeB1koq10jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "print(Counter(y_pred).items())\n",
        "a = pd.read_csv('(1)y679zhao.csv')\n",
        "print(Counter(a['Predicted']).items())"
      ],
      "metadata": {
        "id": "4OjBNVAGynOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#y_pred = [int(i) for i in y_pred]\n",
        "y_pred = pd.DataFrame(y_pred)\n",
        "y_pred.columns = ['Predicted']\n",
        "y_pred.index = y_pred.index\n",
        "y_pred.index.name = 'ID'\n",
        "y_pred.to_csv('y679zhao.csv')"
      ],
      "metadata": {
        "id": "e0fUPZoeTIGp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}